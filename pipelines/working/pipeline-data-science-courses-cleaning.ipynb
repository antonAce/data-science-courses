{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "armed-independence",
   "metadata": {},
   "source": [
    "# Online Data Science Courses. Preprocessing pipeline\n",
    "\n",
    "## Data Science courses scraped from the popular online educational platforms\n",
    "\n",
    "\n",
    "### Context\n",
    "\n",
    "Nowadays, online educational platforms provide a vast amount of online courses. For self-learning beginners in Data Science, sometimes it's hard to choose an online course to start. This data was collected with the intent to answer common questions when choosing a new study.\n",
    "\n",
    "\n",
    "### Acknowledgements\n",
    "\n",
    "Data was collected via web scraping from popular online platforms: [Coursera](https://www.coursera.org), [Stepik](https://stepik.org), [Udemy](https://www.udemy.com), [edX](https://www.edx.org), [Pluralsight](https://www.pluralsight.com), [Alison](https://alison.com), [FutureLearn](https://www.futurelearn.com), and [Skillshare](https://www.skillshare.com). From each platform were queried courses only related to the \"Data Science\" topic. The original author of the [image thumbnail](https://unsplash.com/photos/Im7lZjxeLhg) is [Ales Nesetril](https://unsplash.com/@alesnesetril).\n",
    "\n",
    "\n",
    "### Inspiration\n",
    "\n",
    "The primary intent behind collecting courses data is to discover which online platform provides the highest educational quality. Also, further analysis should reveal answers like \"Does a paid course provide higher quality than a free one?\" or \"Which platform is the most suitable for beginners?\".\n",
    "\n",
    "### Pipeline rules\n",
    "\n",
    " 1. Replace `None` in `Level` as `Mixed`, `All Levels` as `Mixed`\n",
    " 2. Valid level values are: `Advanced`, `Mixed`, `Intermediate`, `Beginner`\n",
    " 3. Merge multiple authors with ' ' symbol as a single column\n",
    " 4. Exclude 'Description' column (for V1)\n",
    " 5. Set `Votes_count` as integer without `,` symbol\n",
    " 6. Set `Student_count` as integer without `,` symbol\n",
    " 7. Replace `Introducionary` level with `Beginner` level\n",
    " 8. Remove `\\n\\r\\t` symbols from `Title` column\n",
    " 9. Normalize `Duration` column to the hour count:\n",
    "     - Raw `Skillshare` value is seconds\n",
    " \n",
    "\n",
    "### Scraped URLs\n",
    "\n",
    " - [Coursera](https://www.coursera.org/search?page=1&index=prod_all_launched_products_term_optimization&topic=Data%20Science)\n",
    " - [Stepik](https://stepik.org/catalog/search?lang=en&page=1&q=Data%20Science)\n",
    " - [Udemy](https://www.udemy.com/courses/development/data-science/?p=1)\n",
    " - [edX](https://www.edx.org/search?language=English&subject=Data%20Analysis%20%26%20Statistics&tab=course)\n",
    " - [Pluralsight](https://www.pluralsight.com/search?q=Data%20Science&categories=course)\n",
    " - [Alison](https://alison.com/tag/data-science?page=1)\n",
    " - [FutureLearn](https://www.futurelearn.com/subjects/science-engineering-and-maths-courses/data-science)\n",
    " - [Skillshare](https://www.skillshare.com/search?query=Data%20Science)\n",
    " - [LinkedIn](https://www.linkedin.com/learning/topics/data-science)\n",
    "\n",
    "\n",
    "\n",
    "## Environment preparation\n",
    "\n",
    "Creating Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "!spark-shell --version 2>&1 | sed -n '8,15'p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Online Data Science Courses\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"40G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\")\\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-assistant",
   "metadata": {},
   "source": [
    "## Coursera pipeline preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType()\\\n",
    "            .add(\"title\", StringType(), True)\\\n",
    "            .add(\"description\", StringType(), True)\\\n",
    "            .add(\"authors\", ArrayType(StringType()), True)\\\n",
    "            .add(\"rating\", DoubleType(), True)\\\n",
    "            .add(\"votes_count\", StringType(), True)\\\n",
    "            .add(\"students_count\", StringType(), True)\\\n",
    "            .add(\"level\", StringType(), True)\\\n",
    "            .add(\"duration\", StringType(), True)\\\n",
    "            .add(\"platform\", StringType(), True)\\\n",
    "            .add(\"free\", BooleanType(), True)\n",
    "\n",
    "coursera_dataset = spark.read.format(\"json\")\\\n",
    "            .schema(schema)\\\n",
    "            .load(\"../input/coursera.json\")\n",
    "\n",
    "coursera_dataset.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "coursera_dataset.toPandas().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "re_digits_in_words = re.compile(r'\\b(\\w)*(\\d)(\\w)*\\b')\n",
    "re_redundant_spaces = re.compile(r'[ ]+')\n",
    "\n",
    "\n",
    "def preprocessing_text_pipeline(text: str) -> str:\n",
    "    if text is None:\n",
    "        return None\n",
    "\n",
    "    steps = [\n",
    "        lambda text: text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' '),\n",
    "        # Remove words that contain digits\n",
    "        lambda text: re_digits_in_words.sub('', text),\n",
    "        # Remove redundant spaces between each word\n",
    "        lambda text: re_redundant_spaces.sub(' ', text),\n",
    "        # Strip string\n",
    "        lambda text: text.strip()\n",
    "    ]\n",
    "    \n",
    "    for step in steps:\n",
    "        text = step(text)\n",
    "        \n",
    "    return text\n",
    "\n",
    "\n",
    "def normalize_student_count(student_count: str) -> int:\n",
    "    if student_count is None:\n",
    "        return None\n",
    "    \n",
    "    base_count = float(student_count[:-1])\n",
    "    multiplyer_count = student_count[-1]\n",
    "    \n",
    "    if multiplyer_count == 'm':\n",
    "        return int(base_count * 1000000)\n",
    "    elif multiplyer_count == 'k':\n",
    "        return int(base_count * 1000)\n",
    "    else:\n",
    "        return int(base_count)\n",
    "\n",
    "def normalize_votes_count(votes_count: str) -> int:\n",
    "    if votes_count is None:\n",
    "        return None\n",
    "    \n",
    "    valid_votes_count = votes_count[1:-1]\n",
    "    valid_votes_count = valid_votes_count.replace(',', '')\n",
    "    return int(valid_votes_count)\n",
    "\n",
    "\n",
    "def normalize_authors(authors: list) -> str:\n",
    "    if authors is None or len(authors) == 0:\n",
    "        return None\n",
    "    \n",
    "    return authors[0]\n",
    "\n",
    "\n",
    "def normalize_duration(duration: str) -> float:\n",
    "    if duration is None or \"Approx\" not in duration:\n",
    "        return None\n",
    "    \n",
    "    weeks_and_hours = re.findall(r'\\d+', duration)\n",
    "    \n",
    "    if len(weeks_and_hours) > 1:\n",
    "        return int(weeks_and_hours[0]) * 4 * int(weeks_and_hours[1]) * 1.0\n",
    "    else:\n",
    "        return int(weeks_and_hours[0]) * 1.0\n",
    "\n",
    "\n",
    "preprocessing_text_pipeline_udf = udf(lambda x: preprocessing_text_pipeline(x), StringType())\n",
    "normalize_authors_udf = udf(lambda x: normalize_authors(x), StringType())\n",
    "normalize_student_count_udf = udf(lambda x: normalize_student_count(x), IntegerType())\n",
    "normalize_votes_count_udf = udf(lambda x: normalize_votes_count(x), IntegerType())\n",
    "normalize_duration_udf = udf(lambda x: normalize_duration(x), DoubleType())\n",
    "    \n",
    "coursera_dataset_normalize = coursera_dataset.select(\n",
    "    preprocessing_text_pipeline_udf(col(\"title\")).alias(\"title\"),\n",
    "    normalize_authors_udf(col(\"authors\")).alias(\"author\"),\n",
    "    col(\"rating\"),\n",
    "    normalize_votes_count_udf(col(\"votes_count\")).alias(\"votes_count\"),\n",
    "    normalize_student_count_udf(col(\"students_count\")).alias(\"students_count\"),\n",
    "    col(\"level\"),\n",
    "    normalize_duration_udf(col(\"duration\")).alias(\"duration\"),\n",
    "    col(\"platform\"),\n",
    "    col(\"free\")\n",
    ")\n",
    "\n",
    "coursera_dataset_normalize.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "coursera_dataset_normalize.select(col(\"duration\")).distinct().toPandas().hist(bins=24, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-damage",
   "metadata": {},
   "source": [
    "## Stepik pipeline preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType()\\\n",
    "            .add(\"title\", StringType(), True)\\\n",
    "            .add(\"authors\", ArrayType(StringType()), True)\\\n",
    "            .add(\"rating\", DoubleType(), True)\\\n",
    "            .add(\"votes_count\", DoubleType(), True)\\\n",
    "            .add(\"students_count\", IntegerType(), True)\\\n",
    "            .add(\"level\", StringType(), True)\\\n",
    "            .add(\"duration\", DoubleType(), True)\\\n",
    "            .add(\"platform\", StringType(), True)\\\n",
    "            .add(\"free\", BooleanType(), True)\n",
    "\n",
    "stepik_dataset = spark.read.format(\"json\")\\\n",
    "            .schema(schema)\\\n",
    "            .load(\"../input/stepik.json\")\n",
    "\n",
    "stepik_dataset.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepik_dataset.toPandas().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepik_dataset_normalize = stepik_dataset.select(\n",
    "    preprocessing_text_pipeline_udf(col(\"title\")).alias(\"title\"),\n",
    "    normalize_authors_udf(col(\"authors\")).alias(\"author\"),\n",
    "    col(\"rating\"),\n",
    "    col(\"votes_count\"),\n",
    "    col(\"students_count\"),\n",
    "    col(\"level\"),\n",
    "    col(\"duration\"),\n",
    "    col(\"platform\"),\n",
    "    col(\"free\")\n",
    ")\n",
    "\n",
    "stepik_dataset_normalize.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-riding",
   "metadata": {},
   "source": [
    "## Edx pipeline preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-greeting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "schema = StructType()\\\n",
    "            .add(\"title\", StringType(), True)\\\n",
    "            .add(\"description\", StringType(), True)\\\n",
    "            .add(\"authors\", ArrayType(StringType()), True)\\\n",
    "            .add(\"rating\", DoubleType(), True)\\\n",
    "            .add(\"votes_count\", IntegerType(), True)\\\n",
    "            .add(\"students_count\", StringType(), True)\\\n",
    "            .add(\"level\", StringType(), True)\\\n",
    "            .add(\"duration\", StringType(), True)\\\n",
    "            .add(\"platform\", StringType(), True)\\\n",
    "            .add(\"free\", BooleanType(), True)\n",
    "\n",
    "edx_dataset = spark.read.format(\"json\")\\\n",
    "            .schema(schema)\\\n",
    "            .load(\"../input/edx.json\")\n",
    "\n",
    "edx_dataset.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "edx_dataset.toPandas().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize_authors(authors: list) -> str:\n",
    "    if authors is None or len(authors) == 0:\n",
    "        return None\n",
    "    \n",
    "    return authors[0].replace(\"Institutions: \", \"\").replace(\"Institution: \", \"\")\n",
    "\n",
    "\n",
    "def normalize_students_count(students_count: str) -> int:\n",
    "    if students_count is None:\n",
    "        return None\n",
    "    \n",
    "    students = re.findall(r'\\d+', students_count)\n",
    "\n",
    "    if len(students) == 0:\n",
    "        return None\n",
    "    \n",
    "    return int(\"\".join(students))\n",
    "\n",
    "\n",
    "def normalize_level(level: str) -> str:\n",
    "    level = level.replace(\"Level: \", \"\")\n",
    "    \n",
    "    if level == \"Introductory\":\n",
    "        return \"Beginner\"\n",
    "    else:\n",
    "        return level\n",
    "    \n",
    "    \n",
    "def normalize_duration(duration: str) -> float:\n",
    "    if '\\n' in duration:    \n",
    "        weeks_and_hours = duration.split('\\n')\n",
    "        weeks, hours = weeks_and_hours[0], weeks_and_hours[1]\n",
    "        \n",
    "        weeks_norm = int(re.findall(r'\\d+', weeks)[0])\n",
    "        hours_norm = np.sum([float(int(n)) for n in re.findall(r'\\d+', hours)]) / 2.0\n",
    "        \n",
    "        return weeks_norm * 4.0  \n",
    "    else:\n",
    "        return int(re.findall(r'\\d+', duration)[0]) * 1.0\n",
    "    \n",
    "\n",
    "normalize_authors_udf = udf(lambda x: normalize_authors(x), StringType())\n",
    "normalize_level_udf = udf(lambda x: normalize_level(x), StringType())\n",
    "normalize_students_count_udf = udf(lambda x: normalize_students_count(x), IntegerType())\n",
    "normalize_duration_udf = udf(lambda x: normalize_duration(x), DoubleType())\n",
    "\n",
    "edx_dataset_normalize = edx_dataset.select(\n",
    "    preprocessing_text_pipeline_udf(col(\"title\")).alias(\"title\"),\n",
    "    normalize_authors_udf(col(\"authors\")).alias(\"author\"),\n",
    "    col(\"rating\"),\n",
    "    col(\"votes_count\"),\n",
    "    normalize_students_count_udf(col(\"students_count\")).alias(\"students_count\"),\n",
    "    normalize_level_udf(col(\"level\")).alias(\"level\"),\n",
    "    normalize_duration_udf(col(\"duration\")).alias(\"duration\"),\n",
    "    col(\"platform\"),\n",
    "    col(\"free\")\n",
    ")\n",
    "\n",
    "edx_dataset_normalize.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "edx_dataset_normalize.select(col(\"duration\")).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-jason",
   "metadata": {},
   "source": [
    "## Pluralsight pipeline preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType()\\\n",
    "            .add(\"title\", StringType(), True)\\\n",
    "            .add(\"description\", StringType(), True)\\\n",
    "            .add(\"authors\", ArrayType(StringType()), True)\\\n",
    "            .add(\"rating\", StringType(), True)\\\n",
    "            .add(\"votes_count\", StringType(), True)\\\n",
    "            .add(\"students_count\", StringType(), True)\\\n",
    "            .add(\"level\", StringType(), True)\\\n",
    "            .add(\"duration\", StringType(), True)\\\n",
    "            .add(\"platform\", StringType(), True)\\\n",
    "            .add(\"free\", BooleanType(), True)\n",
    "\n",
    "pluralsight_dataset = spark.read.format(\"json\")\\\n",
    "            .schema(schema)\\\n",
    "            .load(\"../input/pluralsight.json\")\n",
    "\n",
    "pluralsight_dataset.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_authors(authors: list) -> str:\n",
    "    if authors is None or len(authors) == 0:\n",
    "        return None\n",
    "    \n",
    "    return authors[0]\n",
    "\n",
    "\n",
    "def normalize_votes_count(votes_count: str) -> int:\n",
    "    if votes_count is None:\n",
    "        return None\n",
    "    \n",
    "    valid_votes_count = votes_count[1:-1]\n",
    "    valid_votes_count = valid_votes_count.replace(',', '')\n",
    "    return int(valid_votes_count)\n",
    "\n",
    "\n",
    "def normalize_rating(rating: str) -> float:\n",
    "    if len(rating) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        fa_stars = rating.split(';')\n",
    "        total_rating = 0.0\n",
    "        \n",
    "        for fa_star in fa_stars:\n",
    "            if fa_star == 'fa fa-star':\n",
    "                total_rating += 1.0\n",
    "            elif fa_star == 'fa fa-star-half-o':\n",
    "                total_rating += 0.5\n",
    "        \n",
    "        return total_rating\n",
    "    \n",
    "    \n",
    "def normalize_duration(duration: str) -> float:\n",
    "    decimals = re.findall(r'\\d+', duration)\n",
    "    \n",
    "    if len(decimals) == 2:\n",
    "        final_decimal = float(np.round(float(int(decimals[0])) + float(int(decimals[1])) / 60.0, decimals=1))\n",
    "        return final_decimal if final_decimal != 0.0 else 0.1\n",
    "    elif len(decimals) == 1:\n",
    "        final_decimal = float(np.round(float(int(decimals[0])) / 60.0, decimals=1))\n",
    "        return final_decimal if final_decimal != 0.0 else 0.1\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "normalize_authors_udf = udf(lambda x: normalize_authors(x), StringType())\n",
    "normalize_votes_count_udf = udf(lambda x: normalize_votes_count(x), IntegerType())\n",
    "normalize_rating_udf = udf(lambda x: normalize_rating(x), DoubleType())\n",
    "normalize_duration_udf = udf(lambda x: normalize_duration(x), DoubleType())\n",
    "\n",
    "\n",
    "pluralsight_dataset_normalize = pluralsight_dataset.select(\n",
    "    preprocessing_text_pipeline_udf(col(\"title\")).alias(\"title\"),\n",
    "    normalize_authors_udf(col(\"authors\")).alias(\"author\"),\n",
    "    normalize_rating_udf(col(\"rating\")).alias(\"rating\"),\n",
    "    normalize_votes_count_udf(col(\"votes_count\")).alias(\"votes_count\"),\n",
    "    col(\"students_count\"),\n",
    "    col(\"level\"),\n",
    "    normalize_duration_udf(col(\"duration\")).alias(\"duration\"),\n",
    "    col(\"platform\"),\n",
    "    col(\"free\")\n",
    ")\n",
    "\n",
    "pluralsight_dataset_normalize.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "pluralsight_dataset_normalize.select(col(\"duration\")).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-wilson",
   "metadata": {},
   "source": [
    "## Alison pipeline preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType()\\\n",
    "            .add(\"title\", StringType(), True)\\\n",
    "            .add(\"description\", StringType(), True)\\\n",
    "            .add(\"authors\", ArrayType(StringType()), True)\\\n",
    "            .add(\"rating\", StringType(), True)\\\n",
    "            .add(\"votes_count\", StringType(), True)\\\n",
    "            .add(\"students_count\", StringType(), True)\\\n",
    "            .add(\"level\", StringType(), True)\\\n",
    "            .add(\"duration\", StringType(), True)\\\n",
    "            .add(\"platform\", StringType(), True)\\\n",
    "            .add(\"free\", BooleanType(), True)\n",
    "\n",
    "alison_dataset = spark.read.format(\"json\")\\\n",
    "            .schema(schema)\\\n",
    "            .load(\"../input/alison.json\")\n",
    "\n",
    "alison_dataset.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_authors(authors: list) -> str:\n",
    "    if authors is None or len(authors) == 0:\n",
    "        return None\n",
    "    \n",
    "    return authors[0]\n",
    "\n",
    "\n",
    "def normalize_rating(rating: str) -> float:\n",
    "    return None\n",
    "\n",
    "\n",
    "def normalize_students_count(students_count: str) -> int:\n",
    "    return int(students_count.replace(\",\", \"\"))\n",
    "\n",
    "\n",
    "def normalize_duration(duration: str) -> float:\n",
    "    return float(np.round(np.sum([float(n) for n in re.findall(r'[\\d.]+', duration)]) / 2.0, decimals=1))\n",
    "\n",
    "\n",
    "def normalize_level(level: str) -> str:\n",
    "    if level is None:\n",
    "        return \"Mixed\"\n",
    "    \n",
    "\n",
    "normalize_authors_udf = udf(lambda x: normalize_authors(x), StringType())\n",
    "normalize_level_udf = udf(lambda x: normalize_level(x), StringType())\n",
    "normalize_rating_udf = udf(lambda x: normalize_rating(x), DoubleType())\n",
    "normalize_duration_udf = udf(lambda x: normalize_duration(x), DoubleType())\n",
    "normalize_students_count_udf = udf(lambda x: normalize_students_count(x), IntegerType())\n",
    "\n",
    "alison_dataset_normalize = alison_dataset.select(\n",
    "    preprocessing_text_pipeline_udf(col(\"title\")).alias(\"title\"),\n",
    "    normalize_authors_udf(col(\"authors\")).alias(\"author\"),\n",
    "    normalize_rating_udf(col(\"rating\")).alias(\"rating\"),\n",
    "    col(\"votes_count\"),\n",
    "    normalize_students_count_udf(col(\"students_count\")).alias(\"students_count\"),\n",
    "    normalize_level_udf(col(\"level\")).alias(\"level\"),\n",
    "    normalize_duration_udf(col(\"duration\")).alias(\"duration\"),\n",
    "    col(\"platform\"),\n",
    "    col(\"free\")\n",
    ")\n",
    "\n",
    "alison_dataset_normalize.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "alison_dataset_normalize.select(col(\"level\")).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-basics",
   "metadata": {},
   "source": [
    "## Udemy pipeline preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-beatles",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "schema = StructType()\\\n",
    "            .add(\"title\", StringType(), True)\\\n",
    "            .add(\"description\", StringType(), True)\\\n",
    "            .add(\"authors\", ArrayType(StringType()), True)\\\n",
    "            .add(\"rating\", StringType(), True)\\\n",
    "            .add(\"votes_count\", StringType(), True)\\\n",
    "            .add(\"students_count\", StringType(), True)\\\n",
    "            .add(\"level\", StringType(), True)\\\n",
    "            .add(\"duration\", StringType(), True)\\\n",
    "            .add(\"platform\", StringType(), True)\\\n",
    "            .add(\"free\", BooleanType(), True)\n",
    "\n",
    "udemy_dataset = spark.read.format(\"json\")\\\n",
    "            .schema(schema)\\\n",
    "            .load(\"../input/udemy.json\")\n",
    "\n",
    "udemy_dataset.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_level(level: str) -> str:\n",
    "    level = level.replace(\"Level: \", \"\")\n",
    "    \n",
    "    if level == \"Expert\":\n",
    "        return \"Advanced\"\n",
    "    elif level == \"All Levels\":\n",
    "        return \"Mixed\"\n",
    "    else:\n",
    "        return level\n",
    "\n",
    "\n",
    "def normalize_votes_count(votes_count: str) -> int:\n",
    "    return int(re.search(r'\\d+', votes_count.replace(\",\", \"\")).group(0))\n",
    "\n",
    "\n",
    "def normalize_students_count(students_count: str) -> int:\n",
    "    return int(re.search(r'\\d+', students_count.strip(\"\\n\").replace(\",\", \"\")).group(0))\n",
    "\n",
    "\n",
    "def normalize_duration(duration: str) -> float:\n",
    "    if \" total hours\" in duration:\n",
    "        return float(duration.replace(\" total hours\", \"\"))\n",
    "    elif \" total hour\" in duration:\n",
    "        return float(duration.replace(\" total hour\", \"\"))\n",
    "    elif \" total mins\" in duration:\n",
    "        return float(np.round(float(duration.replace(\" total mins\", \"\")) / 60.0, decimals=1))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "normalize_rating_udf = udf(lambda x: float(x), DoubleType())\n",
    "normalize_level_udf = udf(lambda x: normalize_level(x), StringType())\n",
    "normalize_votes_count_udf = udf(lambda x: normalize_votes_count(x), IntegerType())\n",
    "normalize_students_count_udf = udf(lambda x: normalize_students_count(x), IntegerType())\n",
    "normalize_duration_udf = udf(lambda x: normalize_duration(x), DoubleType())\n",
    "\n",
    "udemy_dataset_normalize = udemy_dataset.select(\n",
    "    preprocessing_text_pipeline_udf(col(\"title\")).alias(\"title\"),\n",
    "    normalize_authors_udf(col(\"authors\")).alias(\"author\"),\n",
    "    normalize_rating_udf(col(\"rating\")).alias(\"rating\"),\n",
    "    normalize_votes_count_udf(col(\"votes_count\")).alias(\"votes_count\"),\n",
    "    normalize_students_count_udf(col(\"students_count\")).alias(\"students_count\"),\n",
    "    normalize_level_udf(col(\"level\")).alias(\"level\"),\n",
    "    normalize_duration_udf(col(\"duration\")).alias(\"duration\"),\n",
    "    col(\"platform\"),\n",
    "    col(\"free\")\n",
    ")\n",
    "\n",
    "udemy_dataset_normalize.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "udemy_dataset_normalize.select(col(\"rating\")).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-ghost",
   "metadata": {},
   "source": [
    "## Skillshare pipeline preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType()\\\n",
    "            .add(\"title\", StringType(), True)\\\n",
    "            .add(\"description\", StringType(), True)\\\n",
    "            .add(\"authors\", ArrayType(StringType()), True)\\\n",
    "            .add(\"rating\", StringType(), True)\\\n",
    "            .add(\"votes_count\", StringType(), True)\\\n",
    "            .add(\"students_count\", StringType(), True)\\\n",
    "            .add(\"level\", StringType(), True)\\\n",
    "            .add(\"duration\", StringType(), True)\\\n",
    "            .add(\"platform\", StringType(), True)\\\n",
    "            .add(\"free\", BooleanType(), True)\n",
    "\n",
    "skillshare_dataset = spark.read.format(\"json\")\\\n",
    "            .schema(schema)\\\n",
    "            .load(\"../input/skillshare.json\")\n",
    "\n",
    "skillshare_dataset.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "def normalize_level(level: str) -> str:\n",
    "    correction = {\n",
    "        \"Advanced level\": \"Advanced\",\n",
    "        \"Intermediate level\": \"Intermediate\",\n",
    "        \"Beginner level\": \"Beginner\",\n",
    "        \"All levels\": \"Mixed\",\n",
    "        \"Beg/Int level\": \"Mixed\",\n",
    "        \"--\": \"Mixed\"\n",
    "    }\n",
    "    \n",
    "    if level is None:\n",
    "        return \"Mixed\"\n",
    "    else:\n",
    "        return correction[level]\n",
    "\n",
    "\n",
    "def normalize_votes_count(votes_count: str) -> int:\n",
    "    votes_int = []\n",
    "    votes = votes_count[1:-1].split(\",\")\n",
    "    \n",
    "    for vote in votes:\n",
    "        vote_cleaned = re.search(r\"\\d+\", vote)\n",
    "        votes_int.append(0 if vote_cleaned is None else int(vote_cleaned.group(0)))\n",
    "    \n",
    "    return int(np.sum(votes_int))\n",
    "\n",
    "\n",
    "def normalize_rating(rating: str) -> float:\n",
    "    rating_int = []\n",
    "    rating = ast.literal_eval(rating)\n",
    "    \n",
    "    for mark, ratio in rating.items():\n",
    "        int_ratio = ratio.replace(\"%\", \"\")\n",
    "        ratio = float(int_ratio) / 100.0 if len(int_ratio) > 0 else 0.0\n",
    "        rating_int.append(int(mark) * ratio)\n",
    "    \n",
    "    final_rating = float(np.round(np.sum(rating_int), decimals=1))\n",
    "    return final_rating\n",
    "        \n",
    "    \n",
    "normalize_rating_udf = udf(lambda x: normalize_rating(x), DoubleType())\n",
    "normalize_level_udf = udf(lambda x: normalize_level(x), StringType())\n",
    "normalize_students_count_udf = udf(lambda x: int(x), IntegerType())\n",
    "normalize_duration_udf = udf(lambda x: float(x) / 3600.0, DoubleType())\n",
    "normalize_votes_count_udf = udf(lambda x: normalize_votes_count(x), IntegerType())\n",
    "\n",
    "skillshare_dataset_normalize = skillshare_dataset.select(\n",
    "    preprocessing_text_pipeline_udf(col(\"title\")).alias(\"title\"),\n",
    "    normalize_authors_udf(col(\"authors\")).alias(\"author\"),\n",
    "    normalize_rating_udf(col(\"rating\")).alias(\"rating\"),\n",
    "    normalize_votes_count_udf(col(\"votes_count\")).alias(\"votes_count\"),\n",
    "    normalize_students_count_udf(col(\"students_count\")).alias(\"students_count\"),\n",
    "    normalize_level_udf(col(\"level\")).alias(\"level\"),\n",
    "    normalize_duration_udf(col(\"duration\")).alias(\"duration\"),\n",
    "    col(\"platform\"),\n",
    "    col(\"free\")\n",
    ")\n",
    "\n",
    "skillshare_dataset_normalize.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-turtle",
   "metadata": {},
   "source": [
    "## Futurelearn pipeline preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType()\\\n",
    "            .add(\"title\", StringType(), True)\\\n",
    "            .add(\"description\", StringType(), True)\\\n",
    "            .add(\"authors\", ArrayType(StringType()), True)\\\n",
    "            .add(\"rating\", StringType(), True)\\\n",
    "            .add(\"votes_count\", StringType(), True)\\\n",
    "            .add(\"students_count\", StringType(), True)\\\n",
    "            .add(\"level\", StringType(), True)\\\n",
    "            .add(\"duration\", StringType(), True)\\\n",
    "            .add(\"platform\", StringType(), True)\\\n",
    "            .add(\"free\", BooleanType(), True)\n",
    "\n",
    "futurelearn_dataset = spark.read.format(\"json\")\\\n",
    "            .schema(schema)\\\n",
    "            .load(\"../input/futurelearn.json\")\n",
    "\n",
    "futurelearn_dataset.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_votes_count(votes_count: str) -> int:\n",
    "    if votes_count is None:\n",
    "        return None\n",
    "\n",
    "    return int(re.search(r'\\d+', votes_count).group(0))\n",
    "\n",
    "\n",
    "def normalize_students_count(students_count: str) -> int:\n",
    "    if students_count is None:\n",
    "        return None\n",
    "\n",
    "    return int(re.search(r'\\d+', students_count.replace(\",\", \"\")).group(0))\n",
    "\n",
    "\n",
    "def normalize_duration(duration: str) -> float:\n",
    "    weeks, hours = tuple(duration.split(\";\"))\n",
    "\n",
    "    return float(re.search(r'\\d+', weeks).group(0)) * float(re.search(r'\\d+', hours).group(0))\n",
    "\n",
    "\n",
    "def normalize_rating(rating: str) -> float:\n",
    "    if rating is None:\n",
    "        return None\n",
    "\n",
    "    return float(rating[:3])\n",
    "\n",
    "\n",
    "normalize_rating_udf = udf(lambda x: normalize_rating(x), DoubleType())\n",
    "normalize_votes_count_udf = udf(lambda x: normalize_votes_count(x), IntegerType())\n",
    "normalize_students_count_udf = udf(lambda x: normalize_students_count(x), IntegerType())\n",
    "normalize_duration_udf = udf(lambda x: normalize_duration(x), DoubleType())\n",
    "\n",
    "futurelearn_dataset_normalize = futurelearn_dataset.select(\n",
    "    preprocessing_text_pipeline_udf(col(\"title\")).alias(\"title\"),\n",
    "    preprocessing_text_pipeline_udf(normalize_authors_udf(col(\"authors\"))).alias(\"author\"),\n",
    "    normalize_rating_udf(col(\"rating\")).alias(\"rating\"),\n",
    "    normalize_votes_count_udf(col(\"votes_count\")).alias(\"votes_count\"),\n",
    "    normalize_students_count_udf(col(\"students_count\")).alias(\"students_count\"),\n",
    "    col(\"level\"),\n",
    "    normalize_duration_udf(col(\"duration\")).alias(\"duration\"),\n",
    "    col(\"platform\"),\n",
    "    col(\"free\")\n",
    ")\n",
    "\n",
    "futurelearn_dataset_normalize.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-anderson",
   "metadata": {},
   "source": [
    "## Final dataframe merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = coursera_dataset_normalize\\\n",
    "                .union(stepik_dataset_normalize)\\\n",
    "                .union(edx_dataset_normalize)\\\n",
    "                .union(udemy_dataset_normalize)\\\n",
    "                .union(pluralsight_dataset_normalize)\\\n",
    "                .union(alison_dataset_normalize)\\\n",
    "                .union(skillshare_dataset_normalize)\\\n",
    "                .union(futurelearn_dataset_normalize)\n",
    "\n",
    "final_df = final_df.orderBy(rand())\n",
    "final_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.select(col(\"platform\")).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.distinct().toPandas().to_csv('output/dataframe.csv', header=coursera_dataset_normalize.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
